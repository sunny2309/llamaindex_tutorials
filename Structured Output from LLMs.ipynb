{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5f64ee",
   "metadata": {},
   "source": [
    "# Structured Output from LLMs (LlamaIndex | LlaMa-3 | Groq API)\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. **Load LLM**\n",
    "2. **Define Output Schemas (Pydantic Classes)**\n",
    "3. **Generate Pydantic | JSON Output**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e1656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a6616",
   "metadata": {},
   "source": [
    "## 1. Load LLM\n",
    "\n",
    "* Login to **https://console.groq.com** and create API Key.\n",
    "\n",
    "### Groq Models\n",
    "\n",
    "ID|\tREQUESTS PER MINUTE|\tREQUESTS PER DAY|\tTOKENS PER MINUTE\n",
    "-|-|-|-\n",
    "llama3-70b-8192\t|30\t|14,400\t|6,000\n",
    "llama3-8b-8192\t|30\t|14,400\t|30,000\n",
    "gemma-7b-it\t|30\t|14,400\t|15,000\n",
    "gemma2-9b-it |30\t|14,400\t|15,000\n",
    "mixtral-8x7b-32768\t|30\t|14,400\t|5,000\n",
    "llama3-groq-8b-8192-tool-use-preview|30\t|14,400\t|15,000\n",
    "llama3-groq-70b-8192-tool-use-preview|30\t|14,400\t|15,000\n",
    "\n",
    "\n",
    "#### LlamaIndex Groq Package\n",
    "\n",
    "* **pip install llama-index-llms-groq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ecef04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Groq(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x7f9b186ab4c0>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x7f9ad4c52b00>, completion_to_prompt=<function default_completion_to_prompt at 0x7f9ad4cc7490>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, model='llama3-8b-8192', temperature=0.0, max_tokens=None, logprobs=None, top_logprobs=0, additional_kwargs={}, max_retries=3, timeout=60.0, default_headers=None, reuse_client=True, api_key='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', api_base='https://api.groq.com/openai/v1', api_version='', context_window=3900, is_chat_model=True, is_function_calling_model=True, tokenizer=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.groq import Groq\n",
    "\n",
    "llama3 = Groq(model=\"llama3-8b-8192\", api_key=groq_api_key, temperature=0.0)\n",
    "\n",
    "llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b329155b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text=\"Hello! I'm just an AI, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you may have! How can I assist you today?\", additional_kwargs={}, raw={'id': 'chatcmpl-b8dac03d-3395-474f-b1a9-fc68b7e200c9', 'choices': [Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm just an AI, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to help with any questions or tasks you may have! How can I assist you today?\", role='assistant', function_call=None, tool_calls=None))], 'created': 1721188753, 'model': 'llama3-8b-8192', 'object': 'chat.completion', 'system_fingerprint': 'fp_af05557ca2', 'usage': CompletionUsage(completion_tokens=46, prompt_tokens=16, total_tokens=62, prompt_time=0.003540944, completion_time=0.035589898, total_time=0.039130842), 'x_groq': {'id': 'req_01j2zdg83kebgbha4x9cgkbx40'}}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3.complete(\"Hello, How are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c0330",
   "metadata": {},
   "source": [
    "## 2. Define Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2cd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Class Representing Individual Person.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of the person.\")\n",
    "    age: int = Field(description=\"Age of Person.\")\n",
    "    height: Optional[str] = Field(description=\"Height of Person\")\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: List[Person]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8a335",
   "metadata": {},
   "source": [
    "## 3. Generate Structured Output (Pydantic / JSON Objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b77fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.program import LLMTextCompletionProgram, FunctionCallingProgram\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "\n",
    "prompt_template_str = \"\"\"\\\n",
    "You are an expert data parser. Parse data from user query.\n",
    "\n",
    "If you don't know any field then set it to None.\n",
    "\n",
    "{query}\n",
    "\"\"\"\n",
    "\n",
    "pydantic_data_parser = LLMTextCompletionProgram.from_defaults(\n",
    "    output_parser=PydanticOutputParser(Person),\n",
    "    #output_cls=Person,\n",
    "    prompt_template_str=prompt_template_str,\n",
    "    llm=llama3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1c9eaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Anna', age=20, height='five foot five inch')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pydantic_data_parser(query=\"Anna is 20 years old and five foot five inch.\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401cd8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Anna', 'age': 20, 'height': 'five foot five inch'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80449136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"Anna\", \"age\": 20, \"height\": \"five foot five inch\"}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49137726",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='Sam', age=25, height='5 foot 10 inch')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pydantic_data_parser(query=\"Sam is 25 years old and 5 foot 10 inch.\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307de191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Sam', 'age': 25, 'height': '5 foot 10 inch'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd284037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', age=20, height='five foot five inch')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydantic_data_parser = LLMTextCompletionProgram.from_defaults(\n",
    "    output_parser=PydanticOutputParser(People),\n",
    "    #output_cls=People,\n",
    "    prompt_template_str=prompt_template_str,\n",
    "    llm=llama3\n",
    ")\n",
    "\n",
    "response = pydantic_data_parser(query=\"Anna is 20 years old and five foot five inch.\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c4ab02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Anna', 'age': 20, 'height': 'five foot five inch'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17705003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', age=20, height='five foot five inch'), Person(name='Sam', age=25, height='5 foot 10 inch')])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = pydantic_data_parser(query=\"Anna is 20 years old and five foot five inch. Sam is 25 years old and 5 foot 10 inch.\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1867c9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Anna', 'age': 20, 'height': 'five foot five inch'},\n",
       "  {'name': 'Sam', 'age': 25, 'height': '5 foot 10 inch'}]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11913310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "People(people=[Person(name='Anna', age=20, height='5 foot 5 inch'), Person(name='Sam', age=25, height='5 foot 10 inch'), Person(name='Donna', age=35, height='5 foot 8 inch'), Person(name='Jack', age=45, height='6 foot 2 inch'), Person(name='Elon', age=55, height='6 foot')])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "Anna is 20 years old and five foot five inch. She lives in UK. Currently, she is working as marketing manager.\n",
    "\n",
    "Sam is 25 years old and 5 foot 10 inch. He lives in US. Currently, he is working as product manager at JP Morgan.\n",
    "\n",
    "Donna is 35 years old and 5 foot 8 inch. She lives in Singapore. Currently, she is working as developer advocate.\n",
    "\n",
    "Jack is 45 years old and 6 foot 2 inch. He lives in Germany. Currently, He is CEO at Skype.\n",
    "\n",
    "Elon is 55 years old and 6 foot tall. He lives in US. Currently, He is CEO of Tesla.\n",
    "\"\"\"\n",
    "\n",
    "response = pydantic_data_parser(query=query)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b15ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': [{'name': 'Anna', 'age': 20, 'height': '5 foot 5 inch'},\n",
       "  {'name': 'Sam', 'age': 25, 'height': '5 foot 10 inch'},\n",
       "  {'name': 'Donna', 'age': 35, 'height': '5 foot 8 inch'},\n",
       "  {'name': 'Jack', 'age': 45, 'height': '6 foot 2 inch'},\n",
       "  {'name': 'Elon', 'age': 55, 'height': '6 foot'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f338fe0b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this video, I explained how to generate **structured output (Pydantic | JSON)** using **Open Source LLMs (LlaMa-3)**. For coding, we used **LlamaIndex** framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b87fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
