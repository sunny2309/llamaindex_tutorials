{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12410a5",
   "metadata": {},
   "source": [
    "# Simple RAG Application using LlamaIndex\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. **Load \"llama2\" Model**\n",
    "2. **Load External Data**\n",
    "3. **Build Index**\n",
    "4. **Build Complete RAG Pipeline**\n",
    "\n",
    "### Installation\n",
    "\n",
    "* **pip install llama-index**\n",
    "* **pip install llama-index-core llama-index-readers-file llama-index-llms-ollama llama-index-embeddings-huggingface**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f9286c-e292-444a-985d-0f36a3925e63",
   "metadata": {},
   "source": [
    "## 1. Load llama2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb77b765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama2\", request_timeout=600) #base_url = 'http://localhost:11434',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27de2b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='I\\'m not familiar with a \"Claude-3.\" Could you please provide more context or information about what Claude-3 is? Is it a person, place, or thing? Additionally, what is the relevance of Claude-3 to your inquiry?', additional_kwargs={'model': 'llama2', 'created_at': '2024-03-08T05:43:28.61649818Z', 'done': True, 'context': [518, 25580, 29962, 3532, 14816, 29903, 29958, 5299, 829, 14816, 29903, 6778, 13, 13, 6132, 366, 1073, 1048, 19108, 29899, 29941, 29973, 518, 29914, 25580, 29962, 13, 29902, 29915, 29885, 451, 9985, 411, 263, 376, 20216, 1151, 29899, 29941, 1213, 6527, 366, 3113, 3867, 901, 3030, 470, 2472, 1048, 825, 19108, 29899, 29941, 338, 29973, 1317, 372, 263, 2022, 29892, 2058, 29892, 470, 2655, 29973, 19814, 29892, 825, 338, 278, 29527, 749, 310, 19108, 29899, 29941, 304, 596, 25501, 16129, 29973], 'total_duration': 8422157117, 'load_duration': 249350, 'prompt_eval_duration': 186733000, 'eval_count': 55, 'eval_duration': 8234642000}, raw={'model': 'llama2', 'created_at': '2024-03-08T05:43:28.61649818Z', 'response': 'I\\'m not familiar with a \"Claude-3.\" Could you please provide more context or information about what Claude-3 is? Is it a person, place, or thing? Additionally, what is the relevance of Claude-3 to your inquiry?', 'done': True, 'context': [518, 25580, 29962, 3532, 14816, 29903, 29958, 5299, 829, 14816, 29903, 6778, 13, 13, 6132, 366, 1073, 1048, 19108, 29899, 29941, 29973, 518, 29914, 25580, 29962, 13, 29902, 29915, 29885, 451, 9985, 411, 263, 376, 20216, 1151, 29899, 29941, 1213, 6527, 366, 3113, 3867, 901, 3030, 470, 2472, 1048, 825, 19108, 29899, 29941, 338, 29973, 1317, 372, 263, 2022, 29892, 2058, 29892, 470, 2655, 29973, 19814, 29892, 825, 338, 278, 29527, 749, 310, 19108, 29899, 29941, 304, 596, 25501, 16129, 29973], 'total_duration': 8422157117, 'load_duration': 249350, 'prompt_eval_duration': 186733000, 'eval_count': 55, 'eval_duration': 8234642000}, delta=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm.complete(\"Do you know about Claude-3?\") ## stream_complete() for streaming response\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c66b0097-5d43-4ce0-a9f8-0c8e3f88a025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not familiar with a \"Claude-3.\" Could you please provide more context or information about what Claude-3 is? Is it a person, place, or thing? Additionally, what is the relevance of Claude-3 to your inquiry?\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4765151a-98fa-41cc-aba8-3a29414c7a27",
   "metadata": {},
   "source": [
    "## 2. Load External Documents\n",
    "\n",
    "* **pip install -U bs4 requests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bbf7ab7-44c3-42bc-a880-1e8efee1423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from llama_index.core import Document\n",
    "\n",
    "urls = [\n",
    "        \"https://www.anthropic.com/news/releasing-claude-instant-1-2\",\n",
    "        \"https://www.anthropic.com/news/claude-pro\",\n",
    "        \"https://www.anthropic.com/news/claude-2\",\n",
    "        \"https://www.anthropic.com/news/claude-2-1\",\n",
    "        \"https://www.anthropic.com/news/claude-2-1-prompting\",\n",
    "        \"https://www.anthropic.com/news/claude-3-family\",\n",
    "        \"https://www.anthropic.com/claude\"\n",
    "       ]\n",
    "\n",
    "docs = []\n",
    "\n",
    "for url in urls:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    docs.append(Document(text=soup.text, metadata={\"source\": url}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08c99e48-3da2-43b9-a03e-8cdc260e1872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='1787d631-8b7b-4f46-a12c-1b2f15d76fde', embedding=None, metadata={'source': 'https://www.anthropic.com/news/claude-3-family'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='Introducing the next generation of Claude \\\\ AnthropicClaudeAPIResearchCompanyNewsCareersProductAnnouncementsIntroducing the next generation of ClaudeMar 4, 2024●7 min readTry Claude 3Today, we\\'re announcing the Claude 3 model family, which sets new industry benchmarks across a wide range of cognitive tasks. The family includes three state-of-the-art models in ascending order of capability: Claude 3 Haiku, Claude 3 Sonnet, and Claude 3 Opus. Each successive model offers increasingly powerful performance, allowing users to select the optimal balance of intelligence, speed, and cost for their specific application.Opus and Sonnet are now available to use in claude.ai and the Claude API which is now generally available in 159 countries. Haiku will be available soon.Claude 3 model familyA new standard for intelligenceOpus, our most intelligent model, outperforms its peers on most of the common evaluation benchmarks for AI systems, including undergraduate level expert knowledge (MMLU), graduate level expert reasoning (GPQA), basic mathematics (GSM8K), and more. It exhibits near-human levels of comprehension and fluency on complex tasks, leading the frontier of general intelligence.All Claude 3 models show increased capabilities in analysis and forecasting, nuanced content creation, code generation, and conversing in non-English languages like Spanish, Japanese, and French.Below is a comparison of the Claude 3 models to those of our peers on multiple benchmarks [1] of capability:Near-instant resultsThe Claude 3 models can power live customer chats, auto-completions, and data extraction tasks where responses must be immediate and in real-time.Haiku is the fastest and most cost-effective model on the market for its intelligence category. It can read an information and data dense research paper on arXiv (~10k tokens) with charts and graphs in less than three seconds. Following launch, we expect to improve performance even further.For the vast majority of workloads, Sonnet is 2x faster than Claude 2 and Claude 2.1 with higher levels of intelligence. It excels at tasks demanding rapid responses, like knowledge retrieval or sales automation. Opus delivers similar speeds to Claude 2 and 2.1, but with much higher levels of intelligence.Strong vision capabilitiesThe Claude 3 models have sophisticated vision capabilities on par with other leading models. They can process a wide range of visual formats, including photos, charts, graphs and technical diagrams. We’re particularly excited to provide this new modality to our enterprise customers, some of whom have up to 50% of their knowledge bases encoded in various formats such as PDFs, flowcharts, or presentation slides.Fewer refusalsPrevious Claude models often made unnecessary refusals that suggested a lack of contextual understanding. We’ve made meaningful progress in this area: Opus, Sonnet, and Haiku are significantly less likely to refuse to answer prompts that border on the system’s guardrails than previous generations of models. As shown below, the Claude 3 models show a more nuanced understanding of requests, recognize real harm, and refuse to answer harmless prompts much less often.Improved accuracyBusinesses of all sizes rely on our models to serve their customers, making it imperative for our model outputs to maintain high accuracy at scale. To assess this, we use a large set of complex, factual questions that target known weaknesses in current models. We categorize the responses into correct answers, incorrect answers (or hallucinations), and admissions of uncertainty, where the model says it doesn’t know the answer instead of providing incorrect information. Compared to Claude 2.1, Opus demonstrates a twofold improvement in accuracy (or correct answers) on these challenging open-ended questions while also exhibiting reduced levels of incorrect answers.In addition to producing more trustworthy responses, we will soon enable citations in our Claude 3 models so they can point to precise sentences in reference material to verify their answers.Long context and near-perfect recallThe Claude 3 family of models will initially offer a 200K context window upon launch. However, all three models are capable of accepting inputs exceeding 1 million tokens and we may make this available to select customers who need enhanced processing power.To process long context prompts effectively, models require robust recall capabilities. The \\'Needle In A Haystack\\' (NIAH) evaluation measures a model\\'s ability to accurately recall information from a vast corpus of data. We enhanced the robustness of this benchmark by using one of 30 random needle/question pairs per prompt and testing on a diverse crowdsourced corpus of documents. Claude 3 Opus not only achieved near-perfect recall, surpassing 99% accuracy, but in some cases, it even identified the limitations of the evaluation itself by recognizing that the \"needle\" sentence appeared to be artificially inserted into the original text by a human.Responsible designWe’ve developed the Claude 3 family of models to be as trustworthy as they are capable. We have several dedicated teams that track and mitigate a broad spectrum of risks, ranging from misinformation and CSAM to biological misuse, election interference, and autonomous replication skills. We continue to develop methods such as Constitutional AI that improve the safety and transparency of our models, and have tuned our models to mitigate against privacy issues that could be raised by new modalities.Addressing biases in increasingly sophisticated models is an ongoing effort and we’ve made strides with this new release. As shown in the model card, Claude 3 shows less biases than our previous models according to the Bias Benchmark for Question Answering (BBQ). We remain committed to advancing techniques that reduce biases and promote greater neutrality in our models, ensuring they are not skewed towards any particular partisan stance.While the Claude 3 model family has advanced on key measures of biological knowledge, cyber-related knowledge, and autonomy compared to previous models, it remains at AI Safety Level 2 (ASL-2) per our Responsible Scaling Policy. Our red teaming evaluations (performed in line with our White House commitments and the 2023 US Executive Order) have concluded that the models present negligible potential for catastrophic risk at this time. We will continue to carefully monitor future models to assess their proximity to the ASL-3 threshold. Further safety details are available in the Claude 3 model card.Easier to useThe Claude 3 models are better at following complex, multi-step instructions. They are particularly adept at adhering to brand voice and response guidelines, and developing customer-facing experiences our users can trust. In addition, the Claude 3 models are better at producing popular structured output in formats like JSON—making it simpler to instruct Claude for use cases like natural language classification and sentiment analysis.Model detailsClaude 3 Opus is our most intelligent model, with best-in-market performance on highly complex tasks. It can navigate open-ended prompts and sight-unseen scenarios with remarkable fluency and human-like understanding. Opus shows us the outer limits of what’s possible with generative AI.Cost [Input $/million tokens | Output $/million tokens]$15 | $75Context window200K*Potential usesTask automation: plan and execute complex actions across APIs and databases, interactive codingR&D: research review, brainstorming and hypothesis generation, drug discoveryStrategy: advanced analysis of charts & graphs, financials and market trends, forecastingDifferentiatorHigher intelligence than any other model available.*1M tokens available for specific use cases, please inquire. Claude 3 Sonnet strikes the ideal balance between intelligence and speed—particularly for enterprise workloads. It delivers strong performance at a lower cost compared to its peers, and is engineered for high endurance in large-scale AI deployments.Cost [Input $/million tokens | Output $/million tokens]$3 | $15Context window200KPotential usesData processing: RAG or search & retrieval over vast amounts of knowledgeSales: product recommendations, forecasting, targeted marketingTime-saving tasks: code generation, quality control, parse text from imagesDifferentiatorMore affordable than other models with similar intelligence; better for scale.Claude 3 Haiku is our fastest, most compact model for near-instant responsiveness. It answers simple queries and requests with unmatched speed. Users will be able to build seamless AI experiences that mimic human interactions.Cost [Input $/million tokens | Output $/million tokens]$0.25 | $1.25Context window200KPotential usesCustomer interactions: quick and accurate support in live interactions, translationsContent moderation: catch risky behavior or customer requestsCost-saving tasks: optimized logistics, inventory management, extract knowledge from unstructured dataDifferentiatorSmarter, faster, and more affordable than other models in its intelligence category.Model availabilityOpus and Sonnet are available to use today in our API, which is now generally available, enabling developers to sign up and start using these models immediately. Haiku will be available soon. Sonnet is powering the free experience on claude.ai, with Opus available for Claude Pro subscribers.Sonnet is also available today through Amazon Bedrock and in private preview on Google Cloud’s Vertex AI Model Garden—with Opus and Haiku coming soon to both.Smarter, faster, saferWe do not believe that model intelligence is anywhere near its limits, and we plan to release frequent updates to the Claude 3 model family over the next few months. We\\'re also excited to release a series of features to enhance our models\\' capabilities, particularly for enterprise use cases and large-scale deployments. These new features will include Tool Use (aka function calling), interactive coding (aka REPL), and more advanced agentic capabilities.As we push the boundaries of AI capabilities, we’re equally committed to ensuring that our safety guardrails keep apace with these leaps in performance. Our hypothesis is that being at the frontier of AI development is the most effective way to steer its trajectory towards positive societal outcomes.We’re excited to see what you create with Claude 3 and hope you will give us feedback to make Claude an even more useful assistant and creative companion. To start building with Claude, visit anthropic.com/claude. FootnotesThis table shows comparisons to models currently available commercially that have released evals. Our model card shows comparisons to models that have been announced but not yet released, such as Gemini 1.5 Pro. In addition, we’d like to note that engineers have worked to optimize prompts and few-shot samples for evaluations and reported higher scores for a newer GPT-4T model. Source.ClaudeAPI ResearchCompanyCustomersNewsCareersPress InquiriesSupportStatusTwitterLinkedInTerms of Service – ConsumerTerms of Service – CommercialPrivacy PolicyAcceptable Use PolicyResponsible Disclosure PolicyCompliance© 2024 Anthropic PBC', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974e0860-1ec8-4b16-9463-20c778ac9a68",
   "metadata": {},
   "source": [
    "## 3. Build Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "503fbf66-dfe9-4ba5-8e6e-515f6d980bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7d26843-661d-4f9f-8087-594bffa0d8ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='abfbcab8-72a7-4f60-92b7-125852b402c3', embedding=None, metadata={'source': 'https://www.anthropic.com/news/claude-3-family'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='1787d631-8b7b-4f46-a12c-1b2f15d76fde', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'source': 'https://www.anthropic.com/news/claude-3-family'}, hash='a0d12e9f4fabd8677bc7b8261c6038ffcb44812f5040d50ff3cdfa3ce14cda08'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20e87106-b7d9-43ba-b9ea-bb6ffed1c1f0', node_type=<ObjectType.TEXT: '1'>, metadata={'source': 'https://www.anthropic.com/news/claude-2-1-prompting'}, hash='2405a2348b0251f598512139ff7c12cb01e861b353e1f003b0365a6a9c48e913'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='393bb60a-6e55-4f05-b19e-76e04b3d1dd2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e6c7c2983e3df6abc91ecbaead79d494b2e12fbcd599914a384de332178c9feb')}, text=\"Introducing the next generation of Claude \\\\ AnthropicClaudeAPIResearchCompanyNewsCareersProductAnnouncementsIntroducing the next generation of ClaudeMar 4, 2024●7 min readTry Claude 3Today, we're announcing the Claude 3 model family, which sets new industry benchmarks across a wide range of cognitive tasks. The family includes three state-of-the-art models in ascending order of capability: Claude 3 Haiku, Claude 3 Sonnet, and Claude 3 Opus. Each successive model offers increasingly powerful performance, allowing users to select the optimal balance of intelligence, speed, and cost for their specific application.Opus and Sonnet are now available to use in claude.ai and the Claude API which is now generally available in 159 countries. Haiku will be available soon.Claude 3 model familyA new standard for intelligenceOpus, our most intelligent model, outperforms its peers on most of the common evaluation benchmarks for AI systems, including undergraduate level expert knowledge (MMLU), graduate level expert reasoning (GPQA), basic mathematics (GSM8K), and more. It exhibits near-human levels of comprehension and fluency on complex tasks, leading the frontier of general intelligence.All Claude 3 models show increased capabilities in analysis and forecasting, nuanced content creation, code generation, and conversing in non-English languages like Spanish, Japanese, and French.Below is a comparison of the Claude 3 models to those of our peers on multiple benchmarks [1] of capability:Near-instant resultsThe Claude 3 models can power live customer chats, auto-completions, and data extraction tasks where responses must be immediate and in real-time.Haiku is the fastest and most cost-effective model on the market for its intelligence category. It can read an information and data dense research paper on arXiv (~10k tokens) with charts and graphs in less than three seconds. Following launch, we expect to improve performance even further.For the vast majority of workloads, Sonnet is 2x faster than Claude 2 and Claude 2.1 with higher levels of intelligence. It excels at tasks demanding rapid responses, like knowledge retrieval or sales automation. Opus delivers similar speeds to Claude 2 and 2.1, but with much higher levels of intelligence.Strong vision capabilitiesThe Claude 3 models have sophisticated vision capabilities on par with other leading models. They can process a wide range of visual formats, including photos, charts, graphs and technical diagrams. We’re particularly excited to provide this new modality to our enterprise customers, some of whom have up to 50% of their knowledge bases encoded in various formats such as PDFs, flowcharts, or presentation slides.Fewer refusalsPrevious Claude models often made unnecessary refusals that suggested a lack of contextual understanding. We’ve made meaningful progress in this area: Opus, Sonnet, and Haiku are significantly less likely to refuse to answer prompts that border on the system’s guardrails than previous generations of models. As shown below, the Claude 3 models show a more nuanced understanding of requests, recognize real harm, and refuse to answer harmless prompts much less often.Improved accuracyBusinesses of all sizes rely on our models to serve their customers, making it imperative for our model outputs to maintain high accuracy at scale. To assess this, we use a large set of complex, factual questions that target known weaknesses in current models. We categorize the responses into correct answers, incorrect answers (or hallucinations), and admissions of uncertainty, where the model says it doesn’t know the answer instead of providing incorrect information. Compared to Claude 2.1, Opus demonstrates a twofold improvement in accuracy (or correct answers) on these challenging open-ended questions while also exhibiting reduced levels of incorrect answers.In addition to producing more trustworthy responses, we will soon enable citations in our Claude 3 models so they can point to precise sentences in reference material to verify their answers.Long context and near-perfect recallThe Claude 3 family of models will initially offer a 200K context window upon launch. However, all three models are capable of accepting inputs exceeding 1 million tokens and we may make this available to select customers who need enhanced processing power.To process long context prompts effectively, models require robust recall capabilities. The 'Needle In A Haystack' (NIAH) evaluation measures a model's ability to accurately recall information from a vast corpus of data. We enhanced the robustness of this benchmark by using one of 30 random needle/question pairs per prompt and testing on a diverse crowdsourced corpus of documents.\", start_char_idx=0, end_char_idx=4734, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7437259309545263),\n",
       " NodeWithScore(node=TextNode(id_='88d76dcc-b61b-419e-8492-1ea214cd0323', embedding=None, metadata={'source': 'https://www.anthropic.com/claude'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a7edda2d-f51c-4300-a709-7ad0f3f4ca97', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'source': 'https://www.anthropic.com/claude'}, hash='6cedf8f0faaff6e00d5b7cac2b8ecb4af3d38ed875073a2d5f98b19314dd052a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='77e5d7cb-ea54-4691-9362-02e650d92e48', node_type=<ObjectType.TEXT: '1'>, metadata={'source': 'https://www.anthropic.com/news/claude-3-family'}, hash='e0a7280717c1962262401915df909c535ed07ea55c5223aeebd0bd4fc5a578b0')}, text='Claude \\\\ AnthropicClaudeAPIResearchCompanyNewsCareersTry ClaudeMeet ClaudeClaude is a family of foundational AI models that can be used in a variety of applications. You can talk directly with Claude at claude.ai to brainstorm ideas, analyze images, and process long documents. For developers and businesses, you can now get API access and build directly on top of our AI infrastructure. \\nTry ClaudeGet API AccessClaude’s capabilitiesAdvanced reasoningClaude can perform complex cognitive tasks that go beyond simple pattern recognition or text generationVision analysisTranscribe and analyze almost any static image, from handwritten notes and graphs, to photographsCode generationStart creating websites in HTML and CSS, turning images into structured JSON data, or debugging complex code basesMultilingual processingTranslate between various languages in real-time, practice grammar, or create multi-lingual contentRight-sized for any taskThe Claude 3 family of models offers the best combination of speed and performance for enterprise use cases, at a lower cost than other models on the market.Light & fastHaikuOur fastest model that can execute lightweight actions, with industry-leading speed.Hard-workingSonnetOur best combination of performance and speed for efficient, high-throughput tasks.PowerfulOpusOur most intelligent model, which can handle complex analysis, longer tasks with multiple steps, and higher-order math and coding tasks.CostIntelligenceWhy Claude?SecureEnterprise-grade security & data handlingSOC II Type 2 certified, HIPAA compliance optionsAccessible through AWS (GA) & GCP (in private preview)Trustworthy10x more resistant to jailbreaks and misuseCopyright indemnity protections for paid commercial servicesCapable200K context windowTool UseMultimodalReliableVery low hallucination ratesAccurate over very long documentsPartners building with ClaudeRead Customer StoriesTalk to ClaudeClaude is fast, capable, and truly conversational. Work with Claude to help you do your best workVisit Claude.AIBuild with ClaudeUse the API to integrate Claude into you and your customer workflows to let AI transform your business.Get API AccessCompany NewsSee AllPreparing for global elections in 2024Feb 16, 2024 ● 3 min readThoughts on the US Executive Order, G7 Code of Conduct, and Bletchley Park SummitNov 5, 2023 ● 4 min readDario Amodei’s prepared remarks from the AI Safety Summit on Anthropic’s Responsible Scaling PolicyNov 1, 2023 ● 5 min readClaudeAPI ResearchCompanyCustomersNewsCareersPress InquiriesSupportStatusTwitterLinkedInTerms of Service – ConsumerTerms of Service – CommercialPrivacy PolicyAcceptable Use PolicyResponsible Disclosure PolicyCompliance© 2024 Anthropic PBC', start_char_idx=0, end_char_idx=2711, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7369966936743593)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = index.as_retriever()\n",
    "\n",
    "relevant_docs = retriever.retrieve(\"Do you know about Claude-3?\")\n",
    "\n",
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf35778e-ac47-4acc-8ef1-31ae0e5bbd54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc: {'source': 'https://www.anthropic.com/news/claude-3-family'}\n",
      "Doc: {'source': 'https://www.anthropic.com/claude'}\n"
     ]
    }
   ],
   "source": [
    "for doc in relevant_docs:\n",
    "    print(f\"Doc: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cdc99e-4ad3-4b59-8c27-f3cb412c29e9",
   "metadata": {},
   "source": [
    "## 4. Build Complete RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3cbc73a-0d07-46f3-b72f-570b271a8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = Ollama(model=\"llama2\", request_timeout=600)\n",
    "\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "\n",
    "query_engine = index.as_query_engine() # similarity_top_k, streaming=True\n",
    "\n",
    "query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f271fe39-2cad-417f-aa3b-1fc39cafd1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I am familiar with Claude-3. According to the provided context information, Claude-3 is a family of foundational AI models that can be used in various applications such as brainstorming ideas, analyzing images, and processing long documents. The Claude-3 family includes three state-of-the-art models, Haiku, Sonnet, and Opus, which offer increasingly powerful performance and are available through the Claude API. These models are designed to provide fast and accurate responses, with a 200K context window initially offered upon launch. Additionally, the Claude-3 models have sophisticated vision capabilities, fewer refusals, improved accuracy, and long context and near-perfect recall capabilities.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Do you know about Claude-3?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cf87851-350e-4704-8a74-86a606f99a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.base.response.schema.Response"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "658c9a63-b962-4fcd-a1ba-c03b12063d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abfbcab8-72a7-4f60-92b7-125852b402c3': {'source': 'https://www.anthropic.com/news/claude-3-family'},\n",
       " '88d76dcc-b61b-419e-8492-1ea214cd0323': {'source': 'https://www.anthropic.com/claude'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ac3351e-aa3f-42d7-addf-bf52b3298892",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='abfbcab8-72a7-4f60-92b7-125852b402c3', embedding=None, metadata={'source': 'https://www.anthropic.com/news/claude-3-family'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='1787d631-8b7b-4f46-a12c-1b2f15d76fde', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'source': 'https://www.anthropic.com/news/claude-3-family'}, hash='a0d12e9f4fabd8677bc7b8261c6038ffcb44812f5040d50ff3cdfa3ce14cda08'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='20e87106-b7d9-43ba-b9ea-bb6ffed1c1f0', node_type=<ObjectType.TEXT: '1'>, metadata={'source': 'https://www.anthropic.com/news/claude-2-1-prompting'}, hash='2405a2348b0251f598512139ff7c12cb01e861b353e1f003b0365a6a9c48e913'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='393bb60a-6e55-4f05-b19e-76e04b3d1dd2', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='e6c7c2983e3df6abc91ecbaead79d494b2e12fbcd599914a384de332178c9feb')}, text=\"Introducing the next generation of Claude \\\\ AnthropicClaudeAPIResearchCompanyNewsCareersProductAnnouncementsIntroducing the next generation of ClaudeMar 4, 2024●7 min readTry Claude 3Today, we're announcing the Claude 3 model family, which sets new industry benchmarks across a wide range of cognitive tasks. The family includes three state-of-the-art models in ascending order of capability: Claude 3 Haiku, Claude 3 Sonnet, and Claude 3 Opus. Each successive model offers increasingly powerful performance, allowing users to select the optimal balance of intelligence, speed, and cost for their specific application.Opus and Sonnet are now available to use in claude.ai and the Claude API which is now generally available in 159 countries. Haiku will be available soon.Claude 3 model familyA new standard for intelligenceOpus, our most intelligent model, outperforms its peers on most of the common evaluation benchmarks for AI systems, including undergraduate level expert knowledge (MMLU), graduate level expert reasoning (GPQA), basic mathematics (GSM8K), and more. It exhibits near-human levels of comprehension and fluency on complex tasks, leading the frontier of general intelligence.All Claude 3 models show increased capabilities in analysis and forecasting, nuanced content creation, code generation, and conversing in non-English languages like Spanish, Japanese, and French.Below is a comparison of the Claude 3 models to those of our peers on multiple benchmarks [1] of capability:Near-instant resultsThe Claude 3 models can power live customer chats, auto-completions, and data extraction tasks where responses must be immediate and in real-time.Haiku is the fastest and most cost-effective model on the market for its intelligence category. It can read an information and data dense research paper on arXiv (~10k tokens) with charts and graphs in less than three seconds. Following launch, we expect to improve performance even further.For the vast majority of workloads, Sonnet is 2x faster than Claude 2 and Claude 2.1 with higher levels of intelligence. It excels at tasks demanding rapid responses, like knowledge retrieval or sales automation. Opus delivers similar speeds to Claude 2 and 2.1, but with much higher levels of intelligence.Strong vision capabilitiesThe Claude 3 models have sophisticated vision capabilities on par with other leading models. They can process a wide range of visual formats, including photos, charts, graphs and technical diagrams. We’re particularly excited to provide this new modality to our enterprise customers, some of whom have up to 50% of their knowledge bases encoded in various formats such as PDFs, flowcharts, or presentation slides.Fewer refusalsPrevious Claude models often made unnecessary refusals that suggested a lack of contextual understanding. We’ve made meaningful progress in this area: Opus, Sonnet, and Haiku are significantly less likely to refuse to answer prompts that border on the system’s guardrails than previous generations of models. As shown below, the Claude 3 models show a more nuanced understanding of requests, recognize real harm, and refuse to answer harmless prompts much less often.Improved accuracyBusinesses of all sizes rely on our models to serve their customers, making it imperative for our model outputs to maintain high accuracy at scale. To assess this, we use a large set of complex, factual questions that target known weaknesses in current models. We categorize the responses into correct answers, incorrect answers (or hallucinations), and admissions of uncertainty, where the model says it doesn’t know the answer instead of providing incorrect information. Compared to Claude 2.1, Opus demonstrates a twofold improvement in accuracy (or correct answers) on these challenging open-ended questions while also exhibiting reduced levels of incorrect answers.In addition to producing more trustworthy responses, we will soon enable citations in our Claude 3 models so they can point to precise sentences in reference material to verify their answers.Long context and near-perfect recallThe Claude 3 family of models will initially offer a 200K context window upon launch. However, all three models are capable of accepting inputs exceeding 1 million tokens and we may make this available to select customers who need enhanced processing power.To process long context prompts effectively, models require robust recall capabilities. The 'Needle In A Haystack' (NIAH) evaluation measures a model's ability to accurately recall information from a vast corpus of data. We enhanced the robustness of this benchmark by using one of 30 random needle/question pairs per prompt and testing on a diverse crowdsourced corpus of documents.\", start_char_idx=0, end_char_idx=4734, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7437259309545263),\n",
       " NodeWithScore(node=TextNode(id_='88d76dcc-b61b-419e-8492-1ea214cd0323', embedding=None, metadata={'source': 'https://www.anthropic.com/claude'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a7edda2d-f51c-4300-a709-7ad0f3f4ca97', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'source': 'https://www.anthropic.com/claude'}, hash='6cedf8f0faaff6e00d5b7cac2b8ecb4af3d38ed875073a2d5f98b19314dd052a'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='77e5d7cb-ea54-4691-9362-02e650d92e48', node_type=<ObjectType.TEXT: '1'>, metadata={'source': 'https://www.anthropic.com/news/claude-3-family'}, hash='e0a7280717c1962262401915df909c535ed07ea55c5223aeebd0bd4fc5a578b0')}, text='Claude \\\\ AnthropicClaudeAPIResearchCompanyNewsCareersTry ClaudeMeet ClaudeClaude is a family of foundational AI models that can be used in a variety of applications. You can talk directly with Claude at claude.ai to brainstorm ideas, analyze images, and process long documents. For developers and businesses, you can now get API access and build directly on top of our AI infrastructure. \\nTry ClaudeGet API AccessClaude’s capabilitiesAdvanced reasoningClaude can perform complex cognitive tasks that go beyond simple pattern recognition or text generationVision analysisTranscribe and analyze almost any static image, from handwritten notes and graphs, to photographsCode generationStart creating websites in HTML and CSS, turning images into structured JSON data, or debugging complex code basesMultilingual processingTranslate between various languages in real-time, practice grammar, or create multi-lingual contentRight-sized for any taskThe Claude 3 family of models offers the best combination of speed and performance for enterprise use cases, at a lower cost than other models on the market.Light & fastHaikuOur fastest model that can execute lightweight actions, with industry-leading speed.Hard-workingSonnetOur best combination of performance and speed for efficient, high-throughput tasks.PowerfulOpusOur most intelligent model, which can handle complex analysis, longer tasks with multiple steps, and higher-order math and coding tasks.CostIntelligenceWhy Claude?SecureEnterprise-grade security & data handlingSOC II Type 2 certified, HIPAA compliance optionsAccessible through AWS (GA) & GCP (in private preview)Trustworthy10x more resistant to jailbreaks and misuseCopyright indemnity protections for paid commercial servicesCapable200K context windowTool UseMultimodalReliableVery low hallucination ratesAccurate over very long documentsPartners building with ClaudeRead Customer StoriesTalk to ClaudeClaude is fast, capable, and truly conversational. Work with Claude to help you do your best workVisit Claude.AIBuild with ClaudeUse the API to integrate Claude into you and your customer workflows to let AI transform your business.Get API AccessCompany NewsSee AllPreparing for global elections in 2024Feb 16, 2024 ● 3 min readThoughts on the US Executive Order, G7 Code of Conduct, and Bletchley Park SummitNov 5, 2023 ● 4 min readDario Amodei’s prepared remarks from the AI Safety Summit on Anthropic’s Responsible Scaling PolicyNov 1, 2023 ● 5 min readClaudeAPI ResearchCompanyCustomersNewsCareersPress InquiriesSupportStatusTwitterLinkedInTerms of Service – ConsumerTerms of Service – CommercialPrivacy PolicyAcceptable Use PolicyResponsible Disclosure PolicyCompliance© 2024 Anthropic PBC', start_char_idx=0, end_char_idx=2711, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7369966936743593)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.source_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6b4396-83fc-4afd-a125-f8ca31bd054d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this video, I explained how to create simple **RAG** application using **llamaindex**. Feel free to let me know your views and doubts in comments section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abba5b-37c2-48de-b7fd-d48f58ad9658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
